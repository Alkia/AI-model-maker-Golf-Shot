{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning in the Audio Domain with Model Maker on Golf Shot Classification \n",
    "\n",
    "In this notebook, I use Model Maker for the Audio Domain.\n",
    "\n",
    "It is part of the [Codelab to Customize an Audio model and deploy on Android](https://codelabs.developers.google.com/codelabs/tflite-audio-classification-custom-model-android).\n",
    "\n",
    "I use a custom golf shot dataset and export a TFLite model that can be used on a phone, a TensorFlow.JS model that can be used for inference in the browser and also a SavedModel version that you can use for serving.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tflite-model-maker\n",
      "  Using cached tflite_model_maker-0.4.0-py3-none-any.whl (642 kB)\n",
      "Collecting tensorflow==2.6\n",
      "  Using cached tensorflow-2.6.0-cp38-cp38-win_amd64.whl (423.2 MB)\n",
      "Collecting absl-py>=0.10.0\n",
      "  Using cached absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "Requirement already satisfied: pillow>=7.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tflite-model-maker) (7.2.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tflite-model-maker) (1.15.0)\n",
      "Collecting tensorflow-hub<0.13,>=0.7.0; python_version >= \"3\"\n",
      "  Using cached tensorflow_hub-0.12.0-py2.py3-none-any.whl (108 kB)\n",
      "Collecting sentencepiece>=0.1.91\n",
      "  Using cached sentencepiece-0.1.96-cp38-cp38-win_amd64.whl (1.1 MB)\n",
      "Requirement already satisfied: matplotlib<3.5.0,>=3.0.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tflite-model-maker) (3.2.2)\n",
      "Collecting numba==0.53\n",
      "  Using cached numba-0.53.0-cp38-cp38-win_amd64.whl (2.3 MB)\n",
      "Collecting tensorflow-datasets>=2.1.0\n",
      "  Using cached tensorflow_datasets-4.5.2-py3-none-any.whl (4.2 MB)\n",
      "Collecting flatbuffers==1.12\n",
      "  Using cached flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting neural-structured-learning>=1.3.1\n",
      "  Using cached neural_structured_learning-1.3.1-py2.py3-none-any.whl (120 kB)\n",
      "Collecting tensorflowjs>=2.4.0\n",
      "  Using cached tensorflowjs-3.15.0-py3-none-any.whl (77 kB)\n",
      "Collecting tf-models-official==2.3.0\n",
      "  Using cached tf_models_official-2.3.0-py2.py3-none-any.whl (840 kB)\n",
      "Collecting tflite-support>=0.4.0\n",
      "  Using cached tflite_support-0.4.0-cp38-cp38-win_amd64.whl (441 kB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement scann>=1.2.6 (from tflite-model-maker) (from versions: none)\n",
      "ERROR: No matching distribution found for scann>=1.2.6 (from tflite-model-maker)\n",
      "WARNING: Skipping pycocotools as it is not installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pycocotools\n",
      "  Using cached pycocotools-2.0.4.tar.gz (106 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pycocotools) (3.2.2)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from pycocotools) (1.18.5)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools) (2.8.1)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib>=2.1.0->pycocotools) (1.15.0)\n",
      "Building wheels for collected packages: pycocotools\n",
      "  Building wheel for pycocotools (PEP 517): started\n",
      "  Building wheel for pycocotools (PEP 517): finished with status 'error'\n",
      "Failed to build pycocotools\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Command errored out with exit status 1:\n",
      "   command: 'C:\\ProgramData\\Anaconda3\\python.exe' 'C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pip\\_vendor\\pep517\\_in_process.py' build_wheel 'C:\\Users\\MAXIME~1.CAR\\AppData\\Local\\Temp\\tmpiz_hvk86'\n",
      "       cwd: C:\\Users\\maxime.carpentier\\AppData\\Local\\Temp\\pip-install-ctzuksb_\\pycocotools\n",
      "  Complete output (14 lines):\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-cpython-38\n",
      "  creating build\\lib.win-amd64-cpython-38\\pycocotools\n",
      "  copying pycocotools\\coco.py -> build\\lib.win-amd64-cpython-38\\pycocotools\n",
      "  copying pycocotools\\cocoeval.py -> build\\lib.win-amd64-cpython-38\\pycocotools\n",
      "  copying pycocotools\\mask.py -> build\\lib.win-amd64-cpython-38\\pycocotools\n",
      "  copying pycocotools\\__init__.py -> build\\lib.win-amd64-cpython-38\\pycocotools\n",
      "  running build_ext\n",
      "  skipping 'pycocotools\\_mask.c' Cython extension (up-to-date)\n",
      "  building 'pycocotools._mask' extension\n",
      "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
      "  ----------------------------------------\n",
      "  ERROR: Failed building wheel for pycocotools\n",
      "ERROR: Could not build wheels for pycocotools which use PEP 517 and cannot be installed directly\n"
     ]
    }
   ],
   "source": [
    "# Prerequisites\n",
    "# Model Maker for the Audio domain needs TensorFlow 2.5 to work.\n",
    "! pip install tflite-model-maker tensorflow==2.6\n",
    "# While upgrading the numpy version would often solve the issue, it's not always viable. Good example is the case when you're using tensorflow==2.5 which isn't compatible with the newest numpy version (it requires ~=1.19.2).\n",
    "! pip uninstall pycocotools --yes\n",
    "! pip install pycocotools --no-binary pycocotools\n",
    "# Restart the kernel  manually\n",
    "\n",
    "# Note: If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
    "# You can find the compatibility matrix in TensorFlow Addon's readme:\n",
    "# https://github.com/tensorflow/addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-53eb6876b88e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtflite_model_maker\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtflite_model_maker\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maudio_classifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tflite_model_maker as mm\n",
    "from tflite_model_maker import audio_classifier\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import itertools\n",
    "import glob\n",
    "import random\n",
    "\n",
    "from IPython.display import Audio, Image\n",
    "from scipy.io import wavfile\n",
    "\n",
    "print(f\"TensorFlow Version: {tf.__version__}\")\n",
    "print(f\"Model Maker Version: {mm.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-2c6ea49debee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m birds_dataset_folder = tf.keras.utils.get_file('golf_dataset.zip',\n\u001b[0m\u001b[0;32m      2\u001b[0m                                                 \u001b[1;34m'https://www.dropbox.com/s/4qedjfyzghxfzds/golf_dataset.zip?dl=1'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                                 \u001b[0mcache_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'./'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                                 \u001b[0mcache_subdir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'dataset'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                                 extract=True)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "birds_dataset_folder = tf.keras.utils.get_file('golf_dataset.zip',\n",
    "                                                'https://www.dropbox.com/s/4qedjfyzghxfzds/golf_dataset.zip?dl=1',\n",
    "                                                cache_dir='./',\n",
    "                                                cache_subdir='dataset',\n",
    "                                                extract=True)\n",
    "                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-733b44289b02>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m }\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0mtest_files\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'test/*/*.wav'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_files\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "# @title [Run this] Util functions and data structures.\n",
    "\n",
    "data_dir = './dataset/golf_dataset/small_golf_dataset'\n",
    "\n",
    "bird_code_to_name = {\n",
    "  'driver': 'Driver Strike',\n",
    "  'inthehole': 'The ball is in the hole',\n",
    "  'Iron': 'Iron shot',  \n",
    "  'putter': 'Put hit',\n",
    "  'wood': \"Wood Shot\",   \n",
    "  'Driver': 'Driver Strike',\n",
    "  'Inthehole': 'The ball is in the hole',\n",
    "  'iron': 'Iron shot',  \n",
    "  'Putter': 'Put hit',\n",
    "  'Wood': \"Wood Shot\", \n",
    "}\n",
    "\n",
    "birds_images = {\n",
    "  'driver': 'https://golfworkoutprogram.com/wp-content/uploads/2018/05/golf-driving-tips-943x600.jpg', #  \n",
    "  'Driver': 'https://golfworkoutprogram.com/wp-content/uploads/2018/05/golf-driving-tips-943x600.jpg', #  \n",
    "  'inthehole': 'https://cdn.golfmagic.com/field/image/hfd.jpg', # \n",
    "  'Iron': 'https://golfswingremedy.com/wp-content/uploads/2020/03/How-to-Swing-a-Golf-Iron-golfswingremedy.com_-1024x683-1.jpeg', #  Elaine R. Wilson, www.naturespicsonline.com\n",
    "  'putter': 'https://www.golfibiza.com/wp-content/uploads/putt-golf-1.jpg', # \n",
    "  'Wood': 'https://golf.com/wp-content/uploads/2021/10/GettyImages-1132705407rr.jpg', # \n",
    "  'wood': 'https://golf.com/wp-content/uploads/2021/10/GettyImages-1132705407rr.jpg', # \n",
    "\n",
    "}\n",
    "\n",
    "test_files = os.path.join('/content', data_dir, 'test/*/*.wav')\n",
    "\n",
    "print(test_files)\n",
    "\n",
    "def get_random_audio_file():\n",
    "  test_list = glob.glob(test_files)\n",
    "  print(test_list)\n",
    "  random_audio_path = random.choice(test_list)\n",
    "  print(random_audio_path)\n",
    "  return random_audio_path\n",
    "\n",
    "\n",
    "def show_bird_data(audio_path):\n",
    "  sample_rate, audio_data = wavfile.read(audio_path, 'rb')\n",
    "  print('======= show_bird_data =======')\n",
    "  bird_code = audio_path.split('/')[-2]\n",
    "  print('Code: ' + bird_code)\n",
    "  print('Name: '+bird_code_to_name[bird_code])\n",
    "  print(f'Bird name: {bird_code_to_name[bird_code]}')\n",
    "  print(f'Bird code: {bird_code}')\n",
    "  display(Image(birds_images[bird_code]))\n",
    "\n",
    "  plttitle = f'{bird_code_to_name[bird_code]} ({bird_code})'\n",
    "  plt.title(plttitle)\n",
    "  plt.plot(audio_data)\n",
    "  display(Audio(audio_data, rate=sample_rate))\n",
    "\n",
    "print('functions and data structures created')\n",
    "                                                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playing some audio\n",
    "\n",
    "To have a better understanding about the data, lets listen to a random audio files from the test split.\n",
    "\n",
    "Note: later in this notebook you'll run inference on this audio for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_random_audio_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-87f837d90458>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrandom_audio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_random_audio_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mshow_bird_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_audio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_random_audio_file' is not defined"
     ]
    }
   ],
   "source": [
    "random_audio = get_random_audio_file()\n",
    "show_bird_data(random_audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "\n",
    "When using Model Maker for audio, you have to start with a model spec. This is the base model that your new model will extract information to learn about the new classes. It also affects how the dataset will be transformed to respect the models spec parameters like: sample rate, number of channels.\n",
    "\n",
    "[YAMNet](https://tfhub.dev/google/yamnet/1) is an audio event classifier trained on the AudioSet dataset to predict audio events from the AudioSet ontology.\n",
    "\n",
    "It's input is expected to be at 16kHz and with 1 channel.\n",
    "\n",
    "You don't need to do any resampling yourself. Model Maker takes care of that for you.\n",
    "\n",
    "- `frame_length` is to decide how long each traininng sample is. in this caase EXPECTED_WAVEFORM_LENGTH * 3s\n",
    "\n",
    "- `frame_steps` is to decide how far appart are the training samples. In this case, the ith sample will start at EXPECTED_WAVEFORM_LENGTH * 6s after the (i-1)th sample.\n",
    "\n",
    "The reason to set these values is to work around some limitation in real world dataset.\n",
    "\n",
    "For example, in the bird dataset, birds don't sing all the time. They sing, rest and sing again, with noises in between. Having a long frame would help capture the singing, but setting it too long will reduce the number of samples for training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'audio_classifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-404e8e1f8bcb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m spec = audio_classifier.YamNetSpec(\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mkeep_yamnet_and_custom_heads\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mframe_step\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0maudio_classifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mYamNetSpec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEXPECTED_WAVEFORM_LENGTH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     frame_length=6 * audio_classifier.YamNetSpec.EXPECTED_WAVEFORM_LENGTH)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'audio_classifier' is not defined"
     ]
    }
   ],
   "source": [
    "spec = audio_classifier.YamNetSpec(\n",
    "    keep_yamnet_and_custom_heads=True,\n",
    "    frame_step=3 * audio_classifier.YamNetSpec.EXPECTED_WAVEFORM_LENGTH,\n",
    "    frame_length=6 * audio_classifier.YamNetSpec.EXPECTED_WAVEFORM_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "\n",
    "Model Maker has the API to load the data from a folder and have it in the expected format for the model spec.\n",
    "\n",
    "The train and test split are based on the folders. The validation dataset will be created as 20% of the train split.\n",
    "\n",
    "Note: The `cache=True` is important to make training later faster but it will also require more RAM to hold the data. For the birds dataset that is not a problem since it's only 300MB, but if you use your own data you have to pay attention to it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'audio_classifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-94470d7f9cd3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m train_data = audio_classifier.DataLoader.from_folder(\n\u001b[0m\u001b[0;32m      2\u001b[0m     spec, os.path.join(data_dir, 'train'), cache=True)\n\u001b[0;32m      3\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m test_data = audio_classifier.DataLoader.from_folder(\n\u001b[0;32m      5\u001b[0m     spec, os.path.join(data_dir, 'test'), cache=True)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'audio_classifier' is not defined"
     ]
    }
   ],
   "source": [
    "train_data = audio_classifier.DataLoader.from_folder(\n",
    "    spec, os.path.join(data_dir, 'train'), cache=True)\n",
    "train_data, validation_data = train_data.split(0.8)\n",
    "test_data = audio_classifier.DataLoader.from_folder(\n",
    "    spec, os.path.join(data_dir, 'test'), cache=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "the audio_classifier has the [`create`](https://www.tensorflow.org/lite/api_docs/python/tflite_model_maker/audio_classifier/create) method that creates a model and already start training it. \n",
    "\n",
    "You can customize many parameterss, for more information you can read more details in the documentation.\n",
    "\n",
    "On this first try you'll use all the default configurations and train for 100 epochs.\n",
    "\n",
    "Note: The first epoch takes longer than all the other ones because it's when the cache is created. After that each epoch takes close to 1 second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
